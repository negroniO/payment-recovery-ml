<p align="center">
  <img src="assets/banner.png" width="100%" />
</p>

# ğŸ’³ Payment Recovery Prediction (ML + SQL + Streamlit)

An end-to-end machine learning project that predicts which **failed or unpaid transactions** will be recovered within **30 days**, and prioritizes outreach based on **expected recovered revenue** (amount Ã— probability).  
Built fully from scratch using **Python**, **SQL**, **PostgreSQL**, **scikit-learn**, and **Streamlit**.

## ğŸš€ Live Demo (Streamlit)

ğŸ‘‰ **https://payment-recovery-ml.streamlit.app**

Upload a CSV exported from your `v_feature_view` (or use the included sample file) to:

- score unpaid invoices  
- compute expected recovered revenue  
- see predicted 30-day recovery probability  
- and prioritize outreach based on business impact  

## ğŸ“Œ Project Highlights

- **ğŸ”¥ ML model:** Calibrated Logistic Regression  
- **ğŸ“Š Metrics:** PR AUC, Brier Score, Lift (Top-K vs overall)  
- **ğŸ§  Feature engineering:** customer history, retries, timestamps, device, provider, country  
- **ğŸ’° Expected value ranking:** maximize revenue, not raw probability  
- **ğŸ—„ï¸ SQL pipeline:** raw â†’ staging â†’ feature view (PostgreSQL)  
- **ğŸ“¦ Reproducible:** Conda environment + modular Python scripts  
- **ğŸ–¥ï¸ Interactive UI:** Streamlit app for real-time scoring & prioritization  

## ğŸ›  Tech Stack

**Languages & Core**  
Python, SQL

**Data & ML**  
Pandas, NumPy, scikit-learn

**Database**  
PostgreSQL, psycopg2

**App**  
Streamlit

**Dev Tools**  
Git, Conda, Jupyter

## ğŸ“ Project Structure

```
payment-recovery-ml/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_feature_view.csv
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model_calibrated.joblib
â”œâ”€â”€ notebooks/
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_schema.sql
â”‚   â”œâ”€â”€ 02_staging.sql
â”‚   â””â”€â”€ 03_feature_view.sql
â”œâ”€â”€ train_from_scratch.py
â”œâ”€â”€ score_from_scratch.py
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md
```

## ğŸ—„ï¸ Data Model (PostgreSQL)

The project uses a 3-layer SQL design:

### **1ï¸âƒ£ Raw Layer**  
Stores synthetic transactions: provider, device, timestamps, retries, country, payment_date.

### **2ï¸âƒ£ Staging Layer**  
Cleans data, fixes timestamps, and assigns the binary label:
```
label_recovered_30d = payment_date <= invoice_date + 30 days
```

### **3ï¸âƒ£ Feature View**  
Window functions generate:  
customer history, amount bucket, days since invoice, days since last event, retries, provider, device, country, and more.

## ğŸ¤– Machine Learning Pipeline

- Temporal split (train vs test)  
- Preprocessing (scaling + one-hot encoding)  
- Logistic Regression (balanced)  
- Probability calibration  
- PR AUC + Brier Score evaluation  
- Saves: `model_calibrated.joblib`

## ğŸ“ˆ Scoring Pipeline â€” Expected Value Approach

Instead of sorting only by probability:

```
ev_recovered = amount Ã— p_recover_30d
```

This ranks invoices by **maximum revenue recovery** potential.

Exports:  
- recovery probability  
- expected recovered revenue  
- top-K prioritization  
- timestamped CSV  

## ğŸ–¥ï¸ Streamlit App

Features:  
- Upload CSV or load from Postgres  
- Score invoices  
- View KPIs  
- Prioritize by expected value  
- Download results  

## â–¶ï¸ Run Locally

```
conda env create -f environment.yml
conda activate payrec-ml

python train_from_scratch.py
python score_from_scratch.py

streamlit run app/streamlit_app.py
```

## ğŸ”® Future Enhancements

- XGBoost model  
- SHAP explanations  
- Automated ETL & batch scoring  
- Writebacks to Postgres  
- Monitoring & alerting  
- CI/CD integration  
